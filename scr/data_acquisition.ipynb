{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b297750",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "\n",
    "The purpose of this code is to acquire data on article quality predictions from ORES. \n",
    "\n",
    "The article source data comes from English Wikipedia, the text of which is licensed under \"Creative Commons Attribution Share-Alike license\" (https://en.wikipedia.org/wiki/Wikipedia:Text_of_the_Creative_Commons_Attribution-ShareAlike_3.0_Unported_License)\n",
    "\n",
    "We will be using the MediaWiki REST API for English Wikipedia. To get more information on the API please use the following link: https://www.mediawiki.org/wiki/API:Main_page. The following link may also be helpful when looking for more documentation: https://www.mediawiki.org/wiki/API:Info\n",
    "\n",
    "We will leverage code developed by Dr. David W. McDonald for use in Data 512  which is provided under Creative Commons CC-BY license. (https://creativecommons.org/ and https://creativecommons.org/licenses/by/4.0/). The file can be found at this link: https://drive.google.com/drive/folders/1FtvWV31DHE8HIMdEsPGuCXPz0PMvShfl\n",
    "\n",
    "We will also be using the ORES API. Information on the API itself can be found at https://www.mediawiki.org/wiki/ORES, with original API documentation from https://ores.wikimedia.org/docs and new LiftWing documentation from https://wikitech.wikimedia.org/wiki/Machine_Learning/LiftWing/Usage.\n",
    "\n",
    "We will begin by reading in standard Python libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cf550ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import python libraries\n",
    "import json\n",
    "import time\n",
    "import urllib.parse\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930ec9c0",
   "metadata": {},
   "source": [
    "Next we will read in the us_cities_by_state_SEPT.2023.csv file from raw_data to create a list of articles which we want to feed in to ORES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d16cfd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 22157 page titles captured.\n",
      "WARNING: Page titles are not unique. There are 22157 page titles and 21519 unique titles - a delta of 638.\n"
     ]
    }
   ],
   "source": [
    "#Read in info using pandas\n",
    "cities_by_st_df = pd.read_csv('../raw_data/us_cities_by_state_SEPT.2023.csv')\n",
    "cities_by_st_df.head()\n",
    "\n",
    "#Get a list of page_titles\n",
    "page_titles = list(cities_by_st_df['page_title'])\n",
    "\n",
    "#Check if all the page titles were captures\n",
    "if len(page_titles) == len(cities_by_st_df):\n",
    "    print(\"All {0} page titles captured.\".format(len(page_titles)))\n",
    "else:\n",
    "    print(\"Not all page titles captured\")\n",
    "    \n",
    "#Check if page titles are unique\n",
    "if len(page_titles) == len(cities_by_st_df['page_title'].unique()):\n",
    "    print(\"All {0} page titles are unique.\".format(len(page_titles)))\n",
    "else:\n",
    "    print(\"WARNING: Page titles are not unique. \"+\n",
    "          \"There are {0} page titles and {1} unique titles - \".format(\n",
    "              len(page_titles), len(cities_by_st_df['page_title'].unique()))\n",
    "          + \"a delta of {0}.\".format(len(page_titles)-\n",
    "                                len(cities_by_st_df['page_title'].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac096d9",
   "metadata": {},
   "source": [
    "The user may notice a warning that all page titles are not unique. We will remove duplicated rows in the scraped file us_cities_by_state_SEPT.2023.csv to reduce later processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1a7053f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Page titles are not unique. There are 21525 page titles and 21519 unique titles - a delta of 6.\n"
     ]
    }
   ],
   "source": [
    "#Removing dupes\n",
    "cities_dedupe = cities_by_st_df.drop_duplicates()\n",
    "\n",
    "#Rebuilding the page titles list\n",
    "page_titles_dedupe = list(cities_dedupe['page_title'])\n",
    "\n",
    "#Rechecking if page titles are unique\n",
    "if len(page_titles_dedupe) == len(cities_dedupe['page_title'].unique()):\n",
    "    print(\"All {0} page titles are unique.\".format(len(page_titles_dedupe)))\n",
    "else:\n",
    "    print(\"WARNING: Page titles are not unique. \"+\n",
    "          \"There are {0} page titles and {1} unique titles - \".format(\n",
    "              len(page_titles_dedupe),\n",
    "              len(cities_dedupe['page_title'].unique()))\n",
    "          + \"a delta of {0}.\".format(len(page_titles_dedupe)-\n",
    "                                len(cities_dedupe['page_title'].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c214a0",
   "metadata": {},
   "source": [
    "It is possible that page titles are still not unique. We will visually inspect these page titles to see if there is any way to reduce later processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cd4ec7ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2020 United States census', '2010 United States census', 'County (United States)', 'Population']\n"
     ]
    }
   ],
   "source": [
    "#Getting list of non-unique city names\n",
    "#The following code was taken from Stack Overflow (https://stackoverflow.com/questions/9835762/how-do-i-find-the-duplicates-in-a-list-and-create-another-list-with-them)\n",
    "import collections\n",
    "dupe_titles = [item for item, count in collections.Counter(page_titles_dedupe).items() if count > 1]\n",
    "print(dupe_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0970fd63",
   "metadata": {},
   "source": [
    "Using the files originally obtained for this analysis we will find that there are \"cities\" listed in article titles which are not actually cities at all (e.g., \"Population\" or \"2020 United States census\"). We will remove those non-cities here given that the last n characters of a citie's name should be equal to the value in the first column of the us_cities_by_state_SEPT.2023.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9a82032f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing non-cities from the deduped city file\n",
    "cities_final_df = cities_dedupe.loc[~cities_dedupe['page_title'].isin(dupe_titles)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d9f2205f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#This section has a more robust look at the titles, but there appears\\nto be multiple naming conventions so we'll settle for the easy removals above\\n\\n#making new col w/ last n char from cities_dedupe\\n#cities_dedupe['title_state'] = cities_dedupe['page_title'][:-len(cities_dedupe['state'])]\\n\\n#cities_dedupe.insert(len(cities_dedupe.columns), 'len', len(cities_dedupe['state']))\\ncities_dedupe['title_state'] = None\\nfor index, row in cities_dedupe.iterrows():\\n    row['title_state'] = row['page_title'][-len(row['state']):]\\ncities_dedupe\\ncities_dedupe.loc[cities_dedupe['state'] != cities_dedupe['title_state']]\""
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#This section has a more robust look at the titles, but there appears\n",
    "to be multiple naming conventions so we'll settle for the easy removals above\n",
    "\n",
    "#making new col w/ last n char from cities_dedupe\n",
    "#cities_dedupe['title_state'] = cities_dedupe['page_title'][:-len(cities_dedupe['state'])]\n",
    "\n",
    "#cities_dedupe.insert(len(cities_dedupe.columns), 'len', len(cities_dedupe['state']))\n",
    "cities_dedupe['title_state'] = None\n",
    "for index, row in cities_dedupe.iterrows():\n",
    "    row['title_state'] = row['page_title'][-len(row['state']):]\n",
    "cities_dedupe\n",
    "cities_dedupe.loc[cities_dedupe['state'] != cities_dedupe['title_state']]'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56afcaf1",
   "metadata": {},
   "source": [
    "Now we will access the page info from the MediaWiki REST API for English Wikipedia articles. This code was taken from the file provided by Professor McDonald. We will begin by copying the code which sets up the constants for the API call. Some changes were made to keep comments to 1 line and to alter the name of the example list of articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ca65e885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The basic English Wikipedia API endpoint\n",
    "API_ENWIKIPEDIA_ENDPOINT = \"https://en.wikipedia.org/w/api.php\"\n",
    "\n",
    "# We'll assume that there needs to be some throttling for these requests - \n",
    "#we should always be nice to a free data resource\n",
    "API_LATENCY_ASSUMED = 0.002       # Assuming roughly 2ms latency on the API and network\n",
    "API_THROTTLE_WAIT = (1.0/100.0)-API_LATENCY_ASSUMED\n",
    "\n",
    "# When making automated requests we should include something that is unique \n",
    "#to the person making the request\n",
    "REQUEST_HEADERS = {\n",
    "    'User-Agent': '<ekrolen@uw.edu>, University of Washington, MSDS DATA 512 - AUTUMN 2023',\n",
    "}\n",
    "\n",
    "# Example article list\n",
    "ex_article_titles = [ 'Bison', 'Northern flicker', 'Red squirrel', 'Chinook salmon', 'Horseshoe bat' ]\n",
    "\n",
    "# This is a string of additional page properties that can be returned see \n",
    "#the Info documentation for what can be included. If you don't want any \n",
    "#this can simply be the empty string\n",
    "#PAGEINFO_EXTENDED_PROPERTIES = \"talkid|url|watched|watchers\"\n",
    "PAGEINFO_EXTENDED_PROPERTIES = \"\"\n",
    "\n",
    "# This template lists the basic parameters for making this\n",
    "PAGEINFO_PARAMS_TEMPLATE = {\n",
    "    \"action\": \"query\",\n",
    "    \"format\": \"json\",\n",
    "    \"titles\": \"\",           # simplify - single page title at a time\n",
    "    \"prop\": \"info\",\n",
    "    \"inprop\": PAGEINFO_EXTENDED_PROPERTIES\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395554c2",
   "metadata": {},
   "source": [
    "Next we copy the API request procedure developed by Professor McDonald. Per his comments, \"The API request will be made using one procedure. The idea is to make this reusable. The procedure is parameterized, but relies on the constants above for the important parameters. The underlying assumption is that this will be used to request data for a set of article pages. Therefore the parameter most likely to change is the article_title.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28be2f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Page info requester\n",
    "def request_pageinfo_per_article(article_title = None, \n",
    "                                 endpoint_url = API_ENWIKIPEDIA_ENDPOINT, \n",
    "                                 request_template = PAGEINFO_PARAMS_TEMPLATE,\n",
    "                                 headers = REQUEST_HEADERS):\n",
    "    \n",
    "    # article title can be as a parameter to the call or in the request_template\n",
    "    if article_title:\n",
    "        request_template['titles'] = article_title\n",
    "\n",
    "    if not request_template['titles']:\n",
    "        raise Exception(\"Must supply an article title to make a pageinfo request.\")\n",
    "\n",
    "    # make the request\n",
    "    try:\n",
    "        # we'll wait first, to make sure we don't exceed the limit in the situation where an exception\n",
    "        # occurs during the request processing - throttling is always a good practice with a free\n",
    "        # data source like Wikipedia - or any other community sources\n",
    "        if API_THROTTLE_WAIT > 0.0:\n",
    "            time.sleep(API_THROTTLE_WAIT)\n",
    "        response = requests.get(endpoint_url, headers=headers, params=request_template)\n",
    "        json_response = response.json()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        json_response = None\n",
    "    return json_response\n",
    "\n",
    "#The following code can be run to verify the API is pulling correctly\n",
    "'''print(f\"Getting page info data for: {ex_article_titles[3]}\")\n",
    "info = request_pageinfo_per_article(ex_article_titles[3])\n",
    "print(json.dumps(info,indent=4))'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d8370c",
   "metadata": {},
   "source": [
    "Next we will create a dictionary which contains each of the article titles as keys and their revision ids (lastrevid from request_pageinfo_per_article) for input into the ORES API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f22d9959",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 of 21515 have been written\n",
      "10 of 21515 have been written\n",
      "20 of 21515 have been written\n",
      "30 of 21515 have been written\n",
      "40 of 21515 have been written\n",
      "50 of 21515 have been written\n",
      "60 of 21515 have been written\n",
      "70 of 21515 have been written\n",
      "80 of 21515 have been written\n",
      "90 of 21515 have been written\n",
      "100 of 21515 have been written\n",
      "110 of 21515 have been written\n",
      "120 of 21515 have been written\n",
      "130 of 21515 have been written\n",
      "140 of 21515 have been written\n",
      "150 of 21515 have been written\n",
      "160 of 21515 have been written\n",
      "170 of 21515 have been written\n",
      "180 of 21515 have been written\n",
      "190 of 21515 have been written\n",
      "200 of 21515 have been written\n",
      "210 of 21515 have been written\n",
      "220 of 21515 have been written\n",
      "230 of 21515 have been written\n",
      "240 of 21515 have been written\n",
      "250 of 21515 have been written\n",
      "260 of 21515 have been written\n",
      "270 of 21515 have been written\n",
      "280 of 21515 have been written\n",
      "290 of 21515 have been written\n",
      "300 of 21515 have been written\n",
      "310 of 21515 have been written\n",
      "320 of 21515 have been written\n",
      "330 of 21515 have been written\n",
      "340 of 21515 have been written\n",
      "350 of 21515 have been written\n",
      "360 of 21515 have been written\n",
      "370 of 21515 have been written\n",
      "380 of 21515 have been written\n",
      "390 of 21515 have been written\n",
      "400 of 21515 have been written\n",
      "410 of 21515 have been written\n",
      "420 of 21515 have been written\n",
      "430 of 21515 have been written\n",
      "440 of 21515 have been written\n",
      "450 of 21515 have been written\n",
      "460 of 21515 have been written\n",
      "470 of 21515 have been written\n",
      "480 of 21515 have been written\n",
      "490 of 21515 have been written\n",
      "500 of 21515 have been written\n",
      "510 of 21515 have been written\n",
      "520 of 21515 have been written\n",
      "530 of 21515 have been written\n",
      "540 of 21515 have been written\n",
      "550 of 21515 have been written\n",
      "560 of 21515 have been written\n",
      "570 of 21515 have been written\n",
      "580 of 21515 have been written\n",
      "590 of 21515 have been written\n",
      "600 of 21515 have been written\n",
      "610 of 21515 have been written\n",
      "620 of 21515 have been written\n",
      "630 of 21515 have been written\n",
      "640 of 21515 have been written\n",
      "650 of 21515 have been written\n",
      "660 of 21515 have been written\n",
      "670 of 21515 have been written\n",
      "680 of 21515 have been written\n",
      "690 of 21515 have been written\n",
      "700 of 21515 have been written\n",
      "710 of 21515 have been written\n",
      "720 of 21515 have been written\n",
      "730 of 21515 have been written\n",
      "740 of 21515 have been written\n",
      "750 of 21515 have been written\n",
      "760 of 21515 have been written\n",
      "770 of 21515 have been written\n",
      "780 of 21515 have been written\n",
      "790 of 21515 have been written\n",
      "800 of 21515 have been written\n",
      "810 of 21515 have been written\n",
      "820 of 21515 have been written\n",
      "830 of 21515 have been written\n",
      "840 of 21515 have been written\n",
      "850 of 21515 have been written\n",
      "860 of 21515 have been written\n",
      "870 of 21515 have been written\n",
      "880 of 21515 have been written\n",
      "890 of 21515 have been written\n",
      "900 of 21515 have been written\n",
      "910 of 21515 have been written\n",
      "920 of 21515 have been written\n",
      "930 of 21515 have been written\n",
      "940 of 21515 have been written\n",
      "950 of 21515 have been written\n",
      "960 of 21515 have been written\n",
      "970 of 21515 have been written\n",
      "980 of 21515 have been written\n",
      "990 of 21515 have been written\n",
      "1000 of 21515 have been written\n",
      "1010 of 21515 have been written\n",
      "1020 of 21515 have been written\n",
      "1030 of 21515 have been written\n",
      "1040 of 21515 have been written\n",
      "1050 of 21515 have been written\n",
      "1060 of 21515 have been written\n",
      "1070 of 21515 have been written\n",
      "1080 of 21515 have been written\n",
      "1090 of 21515 have been written\n",
      "1100 of 21515 have been written\n",
      "1110 of 21515 have been written\n",
      "1120 of 21515 have been written\n",
      "1130 of 21515 have been written\n",
      "1140 of 21515 have been written\n",
      "1150 of 21515 have been written\n",
      "1160 of 21515 have been written\n",
      "1170 of 21515 have been written\n",
      "1180 of 21515 have been written\n",
      "1190 of 21515 have been written\n",
      "1200 of 21515 have been written\n",
      "1210 of 21515 have been written\n",
      "1220 of 21515 have been written\n",
      "1230 of 21515 have been written\n",
      "1240 of 21515 have been written\n",
      "1250 of 21515 have been written\n",
      "1260 of 21515 have been written\n",
      "1270 of 21515 have been written\n",
      "1280 of 21515 have been written\n",
      "1290 of 21515 have been written\n",
      "1300 of 21515 have been written\n",
      "1310 of 21515 have been written\n",
      "1320 of 21515 have been written\n",
      "1330 of 21515 have been written\n",
      "1340 of 21515 have been written\n",
      "1350 of 21515 have been written\n",
      "1360 of 21515 have been written\n",
      "1370 of 21515 have been written\n",
      "1380 of 21515 have been written\n",
      "1390 of 21515 have been written\n",
      "1400 of 21515 have been written\n",
      "1410 of 21515 have been written\n",
      "1420 of 21515 have been written\n",
      "1430 of 21515 have been written\n",
      "1440 of 21515 have been written\n",
      "1450 of 21515 have been written\n",
      "1460 of 21515 have been written\n",
      "1470 of 21515 have been written\n",
      "1480 of 21515 have been written\n",
      "1490 of 21515 have been written\n",
      "1500 of 21515 have been written\n",
      "1510 of 21515 have been written\n",
      "1520 of 21515 have been written\n",
      "1530 of 21515 have been written\n",
      "1540 of 21515 have been written\n",
      "1550 of 21515 have been written\n",
      "1560 of 21515 have been written\n",
      "1570 of 21515 have been written\n",
      "1580 of 21515 have been written\n",
      "1590 of 21515 have been written\n",
      "1600 of 21515 have been written\n",
      "1610 of 21515 have been written\n",
      "1620 of 21515 have been written\n",
      "1630 of 21515 have been written\n",
      "1640 of 21515 have been written\n",
      "1650 of 21515 have been written\n",
      "1660 of 21515 have been written\n",
      "1670 of 21515 have been written\n",
      "1680 of 21515 have been written\n",
      "1690 of 21515 have been written\n",
      "1700 of 21515 have been written\n",
      "1710 of 21515 have been written\n",
      "1720 of 21515 have been written\n",
      "1730 of 21515 have been written\n",
      "1740 of 21515 have been written\n",
      "1750 of 21515 have been written\n",
      "1760 of 21515 have been written\n",
      "1770 of 21515 have been written\n",
      "1780 of 21515 have been written\n",
      "1790 of 21515 have been written\n",
      "1800 of 21515 have been written\n",
      "1810 of 21515 have been written\n",
      "1820 of 21515 have been written\n",
      "1830 of 21515 have been written\n",
      "1840 of 21515 have been written\n",
      "1850 of 21515 have been written\n",
      "1860 of 21515 have been written\n",
      "1870 of 21515 have been written\n",
      "1880 of 21515 have been written\n",
      "1890 of 21515 have been written\n",
      "1900 of 21515 have been written\n",
      "1910 of 21515 have been written\n",
      "1920 of 21515 have been written\n",
      "1930 of 21515 have been written\n",
      "1940 of 21515 have been written\n",
      "1950 of 21515 have been written\n",
      "1960 of 21515 have been written\n",
      "1970 of 21515 have been written\n",
      "1980 of 21515 have been written\n",
      "1990 of 21515 have been written\n",
      "2000 of 21515 have been written\n",
      "2010 of 21515 have been written\n",
      "2020 of 21515 have been written\n",
      "2030 of 21515 have been written\n",
      "2040 of 21515 have been written\n",
      "2050 of 21515 have been written\n",
      "2060 of 21515 have been written\n",
      "2070 of 21515 have been written\n",
      "2080 of 21515 have been written\n",
      "2090 of 21515 have been written\n",
      "2100 of 21515 have been written\n",
      "2110 of 21515 have been written\n",
      "2120 of 21515 have been written\n",
      "2130 of 21515 have been written\n",
      "2140 of 21515 have been written\n",
      "2150 of 21515 have been written\n",
      "2160 of 21515 have been written\n",
      "2170 of 21515 have been written\n",
      "2180 of 21515 have been written\n",
      "2190 of 21515 have been written\n",
      "2200 of 21515 have been written\n",
      "2210 of 21515 have been written\n",
      "2220 of 21515 have been written\n",
      "2230 of 21515 have been written\n",
      "2240 of 21515 have been written\n",
      "2250 of 21515 have been written\n",
      "2260 of 21515 have been written\n",
      "2270 of 21515 have been written\n",
      "2280 of 21515 have been written\n",
      "2290 of 21515 have been written\n",
      "2300 of 21515 have been written\n",
      "2310 of 21515 have been written\n",
      "2320 of 21515 have been written\n",
      "2330 of 21515 have been written\n",
      "2340 of 21515 have been written\n",
      "2350 of 21515 have been written\n",
      "2360 of 21515 have been written\n",
      "2370 of 21515 have been written\n",
      "2380 of 21515 have been written\n",
      "2390 of 21515 have been written\n",
      "2400 of 21515 have been written\n",
      "2410 of 21515 have been written\n",
      "2420 of 21515 have been written\n",
      "2430 of 21515 have been written\n",
      "2440 of 21515 have been written\n",
      "2450 of 21515 have been written\n",
      "2460 of 21515 have been written\n",
      "2470 of 21515 have been written\n",
      "2480 of 21515 have been written\n",
      "2490 of 21515 have been written\n",
      "2500 of 21515 have been written\n",
      "2510 of 21515 have been written\n",
      "2520 of 21515 have been written\n",
      "2530 of 21515 have been written\n",
      "2540 of 21515 have been written\n",
      "2550 of 21515 have been written\n",
      "2560 of 21515 have been written\n",
      "2570 of 21515 have been written\n",
      "2580 of 21515 have been written\n",
      "2590 of 21515 have been written\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2600 of 21515 have been written\n",
      "2610 of 21515 have been written\n",
      "2620 of 21515 have been written\n",
      "2630 of 21515 have been written\n",
      "2640 of 21515 have been written\n",
      "2650 of 21515 have been written\n",
      "2660 of 21515 have been written\n",
      "2670 of 21515 have been written\n",
      "2680 of 21515 have been written\n",
      "2690 of 21515 have been written\n",
      "2700 of 21515 have been written\n",
      "2710 of 21515 have been written\n",
      "2720 of 21515 have been written\n",
      "2730 of 21515 have been written\n",
      "2740 of 21515 have been written\n",
      "2750 of 21515 have been written\n",
      "2760 of 21515 have been written\n",
      "2770 of 21515 have been written\n",
      "2780 of 21515 have been written\n",
      "2790 of 21515 have been written\n",
      "2800 of 21515 have been written\n",
      "2810 of 21515 have been written\n",
      "2820 of 21515 have been written\n",
      "2830 of 21515 have been written\n",
      "2840 of 21515 have been written\n",
      "2850 of 21515 have been written\n",
      "2860 of 21515 have been written\n",
      "2870 of 21515 have been written\n",
      "2880 of 21515 have been written\n",
      "2890 of 21515 have been written\n",
      "2900 of 21515 have been written\n",
      "2910 of 21515 have been written\n",
      "2920 of 21515 have been written\n",
      "2930 of 21515 have been written\n",
      "2940 of 21515 have been written\n",
      "2950 of 21515 have been written\n",
      "2960 of 21515 have been written\n",
      "2970 of 21515 have been written\n",
      "2980 of 21515 have been written\n",
      "2990 of 21515 have been written\n",
      "3000 of 21515 have been written\n",
      "3010 of 21515 have been written\n",
      "3020 of 21515 have been written\n",
      "3030 of 21515 have been written\n",
      "3040 of 21515 have been written\n",
      "3050 of 21515 have been written\n",
      "3060 of 21515 have been written\n",
      "3070 of 21515 have been written\n",
      "3080 of 21515 have been written\n",
      "3090 of 21515 have been written\n",
      "3100 of 21515 have been written\n",
      "3110 of 21515 have been written\n",
      "3120 of 21515 have been written\n",
      "3130 of 21515 have been written\n",
      "3140 of 21515 have been written\n",
      "3150 of 21515 have been written\n",
      "3160 of 21515 have been written\n",
      "3170 of 21515 have been written\n",
      "3180 of 21515 have been written\n",
      "3190 of 21515 have been written\n",
      "3200 of 21515 have been written\n",
      "3210 of 21515 have been written\n",
      "3220 of 21515 have been written\n",
      "3230 of 21515 have been written\n",
      "3240 of 21515 have been written\n",
      "3250 of 21515 have been written\n",
      "3260 of 21515 have been written\n",
      "3270 of 21515 have been written\n",
      "3280 of 21515 have been written\n",
      "3290 of 21515 have been written\n",
      "3300 of 21515 have been written\n",
      "3310 of 21515 have been written\n",
      "3320 of 21515 have been written\n",
      "3330 of 21515 have been written\n",
      "3340 of 21515 have been written\n",
      "3350 of 21515 have been written\n",
      "3360 of 21515 have been written\n",
      "3370 of 21515 have been written\n",
      "3380 of 21515 have been written\n",
      "3390 of 21515 have been written\n",
      "3400 of 21515 have been written\n",
      "3410 of 21515 have been written\n",
      "3420 of 21515 have been written\n",
      "3430 of 21515 have been written\n",
      "3440 of 21515 have been written\n",
      "3450 of 21515 have been written\n",
      "3460 of 21515 have been written\n",
      "3470 of 21515 have been written\n",
      "3480 of 21515 have been written\n",
      "3490 of 21515 have been written\n",
      "3500 of 21515 have been written\n",
      "3510 of 21515 have been written\n",
      "3520 of 21515 have been written\n",
      "3530 of 21515 have been written\n",
      "3540 of 21515 have been written\n",
      "3550 of 21515 have been written\n",
      "3560 of 21515 have been written\n",
      "3570 of 21515 have been written\n",
      "3580 of 21515 have been written\n",
      "3590 of 21515 have been written\n",
      "3600 of 21515 have been written\n",
      "3610 of 21515 have been written\n",
      "3620 of 21515 have been written\n",
      "3630 of 21515 have been written\n",
      "3640 of 21515 have been written\n",
      "3650 of 21515 have been written\n",
      "3660 of 21515 have been written\n",
      "3670 of 21515 have been written\n",
      "3680 of 21515 have been written\n",
      "3690 of 21515 have been written\n",
      "3700 of 21515 have been written\n",
      "3710 of 21515 have been written\n",
      "3720 of 21515 have been written\n",
      "3730 of 21515 have been written\n",
      "3740 of 21515 have been written\n",
      "3750 of 21515 have been written\n",
      "3760 of 21515 have been written\n",
      "3770 of 21515 have been written\n",
      "3780 of 21515 have been written\n",
      "3790 of 21515 have been written\n",
      "3800 of 21515 have been written\n",
      "3810 of 21515 have been written\n",
      "3820 of 21515 have been written\n",
      "3830 of 21515 have been written\n",
      "3840 of 21515 have been written\n",
      "3850 of 21515 have been written\n",
      "3860 of 21515 have been written\n",
      "3870 of 21515 have been written\n",
      "3880 of 21515 have been written\n",
      "3890 of 21515 have been written\n",
      "3900 of 21515 have been written\n",
      "3910 of 21515 have been written\n",
      "3920 of 21515 have been written\n",
      "3930 of 21515 have been written\n",
      "3940 of 21515 have been written\n",
      "3950 of 21515 have been written\n",
      "3960 of 21515 have been written\n",
      "3970 of 21515 have been written\n",
      "3980 of 21515 have been written\n",
      "3990 of 21515 have been written\n",
      "4000 of 21515 have been written\n",
      "4010 of 21515 have been written\n",
      "4020 of 21515 have been written\n",
      "4030 of 21515 have been written\n",
      "4040 of 21515 have been written\n",
      "4050 of 21515 have been written\n",
      "4060 of 21515 have been written\n",
      "4070 of 21515 have been written\n",
      "4080 of 21515 have been written\n",
      "4090 of 21515 have been written\n",
      "4100 of 21515 have been written\n",
      "4110 of 21515 have been written\n",
      "4120 of 21515 have been written\n",
      "4130 of 21515 have been written\n",
      "4140 of 21515 have been written\n",
      "4150 of 21515 have been written\n",
      "4160 of 21515 have been written\n",
      "4170 of 21515 have been written\n",
      "4180 of 21515 have been written\n",
      "4190 of 21515 have been written\n",
      "4200 of 21515 have been written\n",
      "4210 of 21515 have been written\n",
      "4220 of 21515 have been written\n",
      "4230 of 21515 have been written\n",
      "4240 of 21515 have been written\n",
      "4250 of 21515 have been written\n",
      "4260 of 21515 have been written\n",
      "4270 of 21515 have been written\n",
      "4280 of 21515 have been written\n",
      "4290 of 21515 have been written\n",
      "4300 of 21515 have been written\n",
      "4310 of 21515 have been written\n",
      "4320 of 21515 have been written\n",
      "4330 of 21515 have been written\n",
      "4340 of 21515 have been written\n",
      "4350 of 21515 have been written\n",
      "4360 of 21515 have been written\n",
      "4370 of 21515 have been written\n",
      "4380 of 21515 have been written\n",
      "('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [108]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(article_titles)):\n\u001b[0;32m     10\u001b[0m     info \u001b[38;5;241m=\u001b[39m request_pageinfo_per_article(article_titles[i])\n\u001b[1;32m---> 11\u001b[0m     page_info_dict[article_titles[i]] \u001b[38;5;241m=\u001b[39m \u001b[43minfo\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mquery\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpages\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;28mlist\u001b[39m(info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpages\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mkeys())[\u001b[38;5;241m0\u001b[39m]][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlastrevid\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     13\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mstr\u001b[39m(i)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m of \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mlen\u001b[39m(article_titles))\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m have been written\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "#Creating the final list of titles to pull\n",
    "article_titles = list(cities_final_df['page_title'])\n",
    "\n",
    "#Pulling lastrevid for all of the articles & saving in a dictionary\n",
    "page_info_dict = {}\n",
    "for i in range(len(article_titles)):\n",
    "    info = request_pageinfo_per_article(article_titles[i])\n",
    "    page_info_dict[article_titles[i]] = info['query']['pages'][list(info['query']['pages'].keys())[0]]['lastrevid']\n",
    "    if i%10 == 0:\n",
    "        print(str(i)+\" of \"+str(len(article_titles))+\" have been written\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "da54b081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['St. Peter, Illinois', 'St. Rose, Illinois', 'Salem, Illinois', 'Sammons Point, Illinois', 'Sandoval, Illinois', 'Sandwich, Illinois', 'San Jose, Illinois', 'Sauget, Illinois', 'Sauk Village, Illinois', 'Saunemin, Illinois', 'Savanna, Illinois', 'Savoy, Illinois', 'Sawyerville, Illinois', 'Saybrook, Illinois', 'Scales Mound, Illinois', 'Schaumburg, Illinois', 'Schiller Park, Illinois', 'Schram City, Illinois', 'Sciota, Illinois', 'Scottville, Illinois']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"little_page_info_dict = {}\\nfor i in range(len(little_list)):\\n    info = request_pageinfo_per_article(little_list[i])\\n    little_page_info_dict[article_titles[i]] = info['query']['pages'][list(info['query']['pages'].keys())[0]]['lastrevid']\\n    print(info)\""
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "little_list = article_titles[4370:4390]\n",
    "print(little_list)\n",
    "'''little_page_info_dict = {}\n",
    "for i in range(len(little_list)):\n",
    "    info = request_pageinfo_per_article(little_list[i])\n",
    "    little_page_info_dict[article_titles[i]] = info['query']['pages'][list(info['query']['pages'].keys())[0]]['lastrevid']\n",
    "    print(info)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd01616",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c00e8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9d7205",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d47fbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76193831",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b947b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
